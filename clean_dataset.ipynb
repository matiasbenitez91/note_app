{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import pickle\n",
    "from random import sample \n",
    "data=pd.read_csv(\"imdb_master.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data.loc[data.label.apply(lambda x: x==\"neg\" or x==\"pos\"),:]\n",
    "data['label']=data.label.apply(lambda x: 1 if x==\"pos\" else 0)\n",
    "data=data.sample(5000, random_state=123)\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_test=sample(range(5000),300)\n",
    "index_train=list(set(range(5000)).difference(set(index_test)))\n",
    "init_train=sample(index_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),\\.!?]\", \" \", string)  \n",
    "    string = re.sub(r\"[^A-Za-z]\", \" \", string)  # remove numbers\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"e\\.g\\.,\", \" \", string) \n",
    "    string = re.sub(r\"a\\.k\\.a\\.\", \" \", string) \n",
    "    string = re.sub(r\"i\\.e\\.,\", \" \", string) \n",
    "    string = re.sub(r\"i\\.e\\.\", \" \", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"\\'\", \"\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"br\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" ( \", string) \n",
    "    string = re.sub(r\"\\)\", \" ) \", string) \n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\.\", \" . \", string)  \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string) \n",
    "    string = re.sub(r\"u\\.s\\.\", \" us \", string)\n",
    "    return string.strip().lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clean = [clean_str(l) for l in data['review']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "#create list to construct vocabulary\n",
    "#clean_text_all = train_clean+test_clean\n",
    "word_clean_count = Counter(list(itertools.chain.from_iterable(text_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dict of unique words\n",
    "v_clean = [x for x, y in word_clean_count.items() if y >=5]\n",
    "v_clean_all = [x for x, y in word_clean_count.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create vocabulary and inverse vocabulary. Words with frequency >5\n",
    "inv_vocabulary_clean ={}\n",
    "inv_vocabulary_clean[0] = 'END'\n",
    "inv_vocabulary_clean[1] = 'UNK'\n",
    "inv_vocabulary_clean[2] = '<PAD/>'\n",
    "vocabulary_clean ={}\n",
    "vocabulary_clean['END'] = 0\n",
    "vocabulary_clean['UNK'] = 1\n",
    "vocabulary_clean['<PAD/>'] = 2\n",
    "ix=3\n",
    "for v in v_clean_all:\n",
    "    if v in v_clean:\n",
    "        vocabulary_clean[v] = ix\n",
    "        inv_vocabulary_clean[ix] = v\n",
    "        ix +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to convert list of words to list of id's\n",
    "def convert_word_to_ix_clean(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        temp = []\n",
    "        for w in sent:\n",
    "            if w in vocabulary_clean:\n",
    "                temp.append(vocabulary_clean.get(w,1))\n",
    "            else:\n",
    "                temp.append(1)\n",
    "        temp.append(0)\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert list of words to list of id's\n",
    "clean_num = convert_word_to_ix_clean(text_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_clean_num, train_x_clean, label_L=[clean_num[x] for x in init_train], [text_clean[x] for x in init_train], [data.label.tolist()[x] for x in init_train]\n",
    "test_x_clean_num, test_x_clean, label_test=[clean_num[x] for x in index_test], [text_clean[x] for x in index_test], [data.label.tolist()[x] for x in index_test]\n",
    "max_len_x=max([len(x) for x in train_x_clean_num])\n",
    "max_len_test=max([len(x) for x in test_x_clean_num])\n",
    "max_len_unlab=max([len(x) for x in clean_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model/random_sampling/M0.p', 'wb') as f:\n",
    "    pickle.dump([train_x_clean_num, train_x_clean, label_L, vocabulary_clean, inv_vocabulary_clean, max_len_x], f, protocol=2)  \n",
    "with open('model/random_sampling/test.p', 'wb') as f:\n",
    "    pickle.dump([test_x_clean_num, test_x_clean, label_test, max_len_test], f, protocol=2) \n",
    "with open('model/random_sampling/all_valid_reports.p', 'wb') as f:\n",
    "    pickle.dump([clean_num, text_clean,max_len_unlab], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model_clean = gensim.models.Word2Vec(text_clean, size=300, window=5, min_count=5, workers=4)\n",
    "model_clean.wv.save_word2vec_format('model/random_sampling/CTword2vec_clean','model/random_sampling/CTvocab_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid(report):\n",
    "    if report not in set(index_test) and report not in set(init_train):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def group(report):\n",
    "    if report in set(index_test):\n",
    "        return 'test'\n",
    "    elif report in set(init_train):\n",
    "        return 'control'\n",
    "data['note_clinician']=float('NaN')\n",
    "data['valid']=[valid(x) for x in list(data.index)]\n",
    "data['group']=[group(x) for x in list(data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.drop(['type', 'index','Unnamed: 0',\"file\"], axis=1, inplace=True)\n",
    "\n",
    "data['tokens_num']=[str(x) for x in clean_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"Report#\"]=list(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('database.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('model/random_sampling/database.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model/kidney/train.p', 'wb') as f:\n",
    "    pickle.dump([train_x_clean_num, train_x_clean, label_L, vocabulary_clean, inv_vocabulary_clean, max_len_x], f, protocol=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=pd.read_csv(\"database.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=data.loc[1,\"tokens_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ec6006793f5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\hp\\Anaconda2\\lib\\ast.pyc\u001b[0m in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'malformed string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp\\Anaconda2\\lib\\ast.pyc\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'malformed string'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: malformed string"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3001,\n",
       " 1357,\n",
       " 9240,\n",
       " 6615,\n",
       " 3541,\n",
       " 277,\n",
       " 5870,\n",
       " 12183,\n",
       " 3014,\n",
       " 7063,\n",
       " 977,\n",
       " 8566,\n",
       " 4801,\n",
       " 10467,\n",
       " 11495,\n",
       " 7672,\n",
       " 10024,\n",
       " 3984,\n",
       " 2801,\n",
       " 11197,\n",
       " 8640,\n",
       " 12184,\n",
       " 9194,\n",
       " 7191,\n",
       " 496,\n",
       " 3984,\n",
       " 2037,\n",
       " 5870,\n",
       " 10467,\n",
       " 6279,\n",
       " 11602,\n",
       " 9615,\n",
       " 1357,\n",
       " 9427,\n",
       " 3984,\n",
       " 6114,\n",
       " 1357,\n",
       " 4927,\n",
       " 10467,\n",
       " 11353,\n",
       " 847,\n",
       " 2497,\n",
       " 9417,\n",
       " 9746,\n",
       " 9577,\n",
       " 10326,\n",
       " 4667,\n",
       " 258,\n",
       " 7380,\n",
       " 1832,\n",
       " 431,\n",
       " 8566,\n",
       " 9615,\n",
       " 4667,\n",
       " 657,\n",
       " 3613,\n",
       " 3984,\n",
       " 977,\n",
       " 4801,\n",
       " 3797,\n",
       " 4801,\n",
       " 10467,\n",
       " 7063,\n",
       " 7189,\n",
       " 9311,\n",
       " 1,\n",
       " 3113,\n",
       " 2867,\n",
       " 3984,\n",
       " 9444,\n",
       " 4801,\n",
       " 10129,\n",
       " 6615,\n",
       " 7321,\n",
       " 3984,\n",
       " 10675,\n",
       " 1,\n",
       " 2936,\n",
       " 4794,\n",
       " 347,\n",
       " 2691,\n",
       " 3619,\n",
       " 3984,\n",
       " 5500,\n",
       " 5870,\n",
       " 3984,\n",
       " 6263,\n",
       " 5870,\n",
       " 1,\n",
       " 2936,\n",
       " 10697,\n",
       " 6591,\n",
       " 6615,\n",
       " 6997,\n",
       " 6405,\n",
       " 2867,\n",
       " 3984,\n",
       " 10235,\n",
       " 3984,\n",
       " 9922,\n",
       " 1,\n",
       " 5870,\n",
       " 9175,\n",
       " 6263,\n",
       " 9925,\n",
       " 4794,\n",
       " 10467,\n",
       " 7063,\n",
       " 7285,\n",
       " 10670,\n",
       " 1,\n",
       " 11495,\n",
       " 10326,\n",
       " 4794,\n",
       " 10467,\n",
       " 9907,\n",
       " 1695,\n",
       " 5870,\n",
       " 5235,\n",
       " 6615,\n",
       " 3613,\n",
       " 9690,\n",
       " 3984,\n",
       " 3393,\n",
       " 4794,\n",
       " 10467,\n",
       " 11403,\n",
       " 5375,\n",
       " 431,\n",
       " 7809,\n",
       " 6615,\n",
       " 277,\n",
       " 5870,\n",
       " 141,\n",
       " 3984,\n",
       " 1176,\n",
       " 6142,\n",
       " 7839,\n",
       " 3892,\n",
       " 10467,\n",
       " 12213,\n",
       " 7239,\n",
       " 2675,\n",
       " 5468,\n",
       " 4795,\n",
       " 321,\n",
       " 1011,\n",
       " 6807,\n",
       " 9925,\n",
       " 10634,\n",
       " 10866,\n",
       " 10331,\n",
       " 3984,\n",
       " 11825,\n",
       " 6279,\n",
       " 9509,\n",
       " 10326,\n",
       " 4963,\n",
       " 2033,\n",
       " 2867,\n",
       " 4795,\n",
       " 12401,\n",
       " 4795,\n",
       " 12109,\n",
       " 3214,\n",
       " 9431,\n",
       " 6615,\n",
       " 7282,\n",
       " 3441,\n",
       " 9175,\n",
       " 6227,\n",
       " 1279,\n",
       " 9144,\n",
       " 5870,\n",
       " 85,\n",
       " 2235,\n",
       " 5874,\n",
       " 6804,\n",
       " 10467,\n",
       " 3491,\n",
       " 10326,\n",
       " 6593,\n",
       " 2724,\n",
       " 8926,\n",
       " 11491,\n",
       " 277,\n",
       " 5870,\n",
       " 3984,\n",
       " 11373,\n",
       " 5870,\n",
       " 10947,\n",
       " 7063,\n",
       " 3341,\n",
       " 1357,\n",
       " 9279,\n",
       " 3984,\n",
       " 11474,\n",
       " 347,\n",
       " 1,\n",
       " 7885,\n",
       " 11637,\n",
       " 9417,\n",
       " 3636,\n",
       " 10444,\n",
       " 0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3001,\n",
       " 1357,\n",
       " 9240,\n",
       " 6615,\n",
       " 3541,\n",
       " 277,\n",
       " 5870,\n",
       " 12183,\n",
       " 3014,\n",
       " 7063,\n",
       " 977,\n",
       " 8566,\n",
       " 4801,\n",
       " 10467,\n",
       " 11495,\n",
       " 7672,\n",
       " 10024,\n",
       " 3984,\n",
       " 2801,\n",
       " 11197,\n",
       " 8640,\n",
       " 12184,\n",
       " 9194,\n",
       " 7191,\n",
       " 496,\n",
       " 3984,\n",
       " 2037,\n",
       " 5870,\n",
       " 10467,\n",
       " 6279,\n",
       " 11602,\n",
       " 9615,\n",
       " 1357,\n",
       " 9427,\n",
       " 3984,\n",
       " 6114,\n",
       " 1357,\n",
       " 4927,\n",
       " 10467,\n",
       " 11353,\n",
       " 847,\n",
       " 2497,\n",
       " 9417,\n",
       " 9746,\n",
       " 9577,\n",
       " 10326,\n",
       " 4667,\n",
       " 258,\n",
       " 7380,\n",
       " 1832,\n",
       " 431,\n",
       " 8566,\n",
       " 9615,\n",
       " 4667,\n",
       " 657,\n",
       " 3613,\n",
       " 3984,\n",
       " 977,\n",
       " 4801,\n",
       " 3797,\n",
       " 4801,\n",
       " 10467,\n",
       " 7063,\n",
       " 7189,\n",
       " 9311,\n",
       " 1,\n",
       " 3113,\n",
       " 2867,\n",
       " 3984,\n",
       " 9444,\n",
       " 4801,\n",
       " 10129,\n",
       " 6615,\n",
       " 7321,\n",
       " 3984,\n",
       " 10675,\n",
       " 1,\n",
       " 2936,\n",
       " 4794,\n",
       " 347,\n",
       " 2691,\n",
       " 3619,\n",
       " 3984,\n",
       " 5500,\n",
       " 5870,\n",
       " 3984,\n",
       " 6263,\n",
       " 5870,\n",
       " 1,\n",
       " 2936,\n",
       " 10697,\n",
       " 6591,\n",
       " 6615,\n",
       " 6997,\n",
       " 6405,\n",
       " 2867,\n",
       " 3984,\n",
       " 10235,\n",
       " 3984,\n",
       " 9922,\n",
       " 1,\n",
       " 5870,\n",
       " 9175,\n",
       " 6263,\n",
       " 9925,\n",
       " 4794,\n",
       " 10467,\n",
       " 7063,\n",
       " 7285,\n",
       " 10670,\n",
       " 1,\n",
       " 11495,\n",
       " 10326,\n",
       " 4794,\n",
       " 10467,\n",
       " 9907,\n",
       " 1695,\n",
       " 5870,\n",
       " 5235,\n",
       " 6615,\n",
       " 3613,\n",
       " 9690,\n",
       " 3984,\n",
       " 3393,\n",
       " 4794,\n",
       " 10467,\n",
       " 11403,\n",
       " 5375,\n",
       " 431,\n",
       " 7809,\n",
       " 6615,\n",
       " 277,\n",
       " 5870,\n",
       " 141,\n",
       " 3984,\n",
       " 1176,\n",
       " 6142,\n",
       " 7839,\n",
       " 3892,\n",
       " 10467,\n",
       " 12213,\n",
       " 7239,\n",
       " 2675,\n",
       " 5468,\n",
       " 4795,\n",
       " 321,\n",
       " 1011,\n",
       " 6807,\n",
       " 9925,\n",
       " 10634,\n",
       " 10866,\n",
       " 10331,\n",
       " 3984,\n",
       " 11825,\n",
       " 6279,\n",
       " 9509,\n",
       " 10326,\n",
       " 4963,\n",
       " 2033,\n",
       " 2867,\n",
       " 4795,\n",
       " 12401,\n",
       " 4795,\n",
       " 12109,\n",
       " 3214,\n",
       " 9431,\n",
       " 6615,\n",
       " 7282,\n",
       " 3441,\n",
       " 9175,\n",
       " 6227,\n",
       " 1279,\n",
       " 9144,\n",
       " 5870,\n",
       " 85,\n",
       " 2235,\n",
       " 5874,\n",
       " 6804,\n",
       " 10467,\n",
       " 3491,\n",
       " 10326,\n",
       " 6593,\n",
       " 2724,\n",
       " 8926,\n",
       " 11491,\n",
       " 277,\n",
       " 5870,\n",
       " 3984,\n",
       " 11373,\n",
       " 5870,\n",
       " 10947,\n",
       " 7063,\n",
       " 3341,\n",
       " 1357,\n",
       " 9279,\n",
       " 3984,\n",
       " 11474,\n",
       " 347,\n",
       " 1,\n",
       " 7885,\n",
       " 11637,\n",
       " 9417,\n",
       " 3636,\n",
       " 10444,\n",
       " 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_num[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
