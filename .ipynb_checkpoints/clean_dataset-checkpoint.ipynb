{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import pickle\n",
    "from random import sample \n",
    "data=pd.read_csv(\"imdb_master.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data.loc[data.label.apply(lambda x: x==\"neg\" or x==\"pos\"),:]\n",
    "data['label']=data.label.apply(lambda x: 1 if x==\"pos\" else 0)\n",
    "data=data.sample(5000, random_state=123)\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_test=sample(range(5000),300)\n",
    "index_train=list(set(range(5000)).difference(set(index_test)))\n",
    "init_train=sample(index_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),\\.!?]\", \" \", string)  \n",
    "    string = re.sub(r\"[^A-Za-z]\", \" \", string)  # remove numbers\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string) \n",
    "    string = re.sub(r\"e\\.g\\.,\", \" \", string) \n",
    "    string = re.sub(r\"a\\.k\\.a\\.\", \" \", string) \n",
    "    string = re.sub(r\"i\\.e\\.,\", \" \", string) \n",
    "    string = re.sub(r\"i\\.e\\.\", \" \", string) \n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"\\'\", \"\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"br\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" ( \", string) \n",
    "    string = re.sub(r\"\\)\", \" ) \", string) \n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\.\", \" . \", string)  \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string) \n",
    "    string = re.sub(r\"u\\.s\\.\", \" us \", string)\n",
    "    return string.strip().lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clean = [clean_str(l) for l in data['review']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "#create list to construct vocabulary\n",
    "#clean_text_all = train_clean+test_clean\n",
    "word_clean_count = Counter(list(itertools.chain.from_iterable(text_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dict of unique words\n",
    "v_clean = [x for x, y in word_clean_count.items() if y >=5]\n",
    "v_clean_all = [x for x, y in word_clean_count.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create vocabulary and inverse vocabulary. Words with frequency >5\n",
    "inv_vocabulary_clean ={}\n",
    "inv_vocabulary_clean[0] = 'END'\n",
    "inv_vocabulary_clean[1] = 'UNK'\n",
    "inv_vocabulary_clean[2] = '<PAD/>'\n",
    "vocabulary_clean ={}\n",
    "vocabulary_clean['END'] = 0\n",
    "vocabulary_clean['UNK'] = 1\n",
    "vocabulary_clean['<PAD/>'] = 2\n",
    "ix=3\n",
    "for v in v_clean_all:\n",
    "    if v in v_clean:\n",
    "        vocabulary_clean[v] = ix\n",
    "        inv_vocabulary_clean[ix] = v\n",
    "        ix +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to convert list of words to list of id's\n",
    "def convert_word_to_ix_clean(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        temp = []\n",
    "        for w in sent:\n",
    "            if w in vocabulary_clean:\n",
    "                temp.append(vocabulary_clean.get(w,1))\n",
    "            else:\n",
    "                temp.append(1)\n",
    "        temp.append(0)\n",
    "        result.append(temp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert list of words to list of id's\n",
    "clean_num = convert_word_to_ix_clean(text_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x_clean_num, train_x_clean, label_L=[clean_num[x] for x in init_train], [text_clean[x] for x in init_train], [data.label.tolist()[x] for x in init_train]\n",
    "test_x_clean_num, test_x_clean, label_test=[clean_num[x] for x in index_test], [text_clean[x] for x in index_test], [data.label.tolist()[x] for x in index_test]\n",
    "max_len_x=max([len(x) for x in train_x_clean_num])\n",
    "max_len_test=max([len(x) for x in test_x_clean_num])\n",
    "max_len_unlab=max([len(x) for x in clean_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model/random_sampling/M0.p', 'wb') as f:\n",
    "    pickle.dump([train_x_clean_num, train_x_clean, label_L, vocabulary_clean, inv_vocabulary_clean, max_len_x], f, protocol=2)  \n",
    "with open('model/random_sampling/test.p', 'wb') as f:\n",
    "    pickle.dump([test_x_clean_num, test_x_clean, label_test, max_len_test], f, protocol=2) \n",
    "with open('model/random_sampling/all_valid_reports.p', 'wb') as f:\n",
    "    pickle.dump([clean_num, text_clean,max_len_unlab], f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "model_clean = gensim.models.Word2Vec(text_clean, size=300, window=5, min_count=5, workers=4)\n",
    "model_clean.wv.save_word2vec_format('model/random_sampling/CTword2vec_clean','model/random_sampling/CTvocab_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid(report):\n",
    "    if report not in set(index_test) and report not in set(init_train):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def group(report):\n",
    "    if report in set(index_test):\n",
    "        return 'test'\n",
    "    elif report in set(init_train):\n",
    "        return 'control'\n",
    "data['note_clinician']=float('NaN')\n",
    "data['valid']=[valid(x) for x in list(data.index)]\n",
    "data['group']=[group(x) for x in list(data.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.drop(['type', 'index','Unnamed: 0',\"file\"], axis=1, inplace=True)\n",
    "\n",
    "data['tokens_num']=[str(x) for x in clean_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"Report#\"]=list(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('database.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('model/random_sampling/database.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model/kidney/train.p', 'wb') as f:\n",
    "    pickle.dump([train_x_clean_num, train_x_clean, label_L, vocabulary_clean, inv_vocabulary_clean, max_len_x], f, protocol=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=pd.read_csv(\"database.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>note_clinician</th>\n",
       "      <th>valid</th>\n",
       "      <th>group</th>\n",
       "      <th>tokens_num</th>\n",
       "      <th>Report#</th>\n",
       "      <th>determinants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>You'll feel like you've experienced a vacation...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[10421, 5344, 4306, 2217, 10421, 6946, 7500, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bela Lugosi gets to play one of his rare good ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>[3001, 1357, 9240, 6615, 3541, 277, 5870, 1218...</td>\n",
       "      <td>1</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>When you wish for the dragon to eat every cast...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2444, 10421, 5475, 3214, 3984, 1961, 6615, 77...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sorry, but Jacqueline Hyde (get it??? - Jack L...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1531, 5468, 6924, 6824, 1832, 4795, 8540, 840...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Unfortunately for Sarah Silverman this show do...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8827, 3214, 802, 5633, 9925, 8072, 4455, 7380...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  label  \\\n",
       "0           0  You'll feel like you've experienced a vacation...      0   \n",
       "1           1  Bela Lugosi gets to play one of his rare good ...      1   \n",
       "2           2  When you wish for the dragon to eat every cast...      0   \n",
       "3           3  Sorry, but Jacqueline Hyde (get it??? - Jack L...      0   \n",
       "4           4  Unfortunately for Sarah Silverman this show do...      0   \n",
       "\n",
       "   note_clinician  valid group  \\\n",
       "0             NaN   True   NaN   \n",
       "1             NaN  False  test   \n",
       "2             NaN   True   NaN   \n",
       "3             NaN   True   NaN   \n",
       "4             NaN   True   NaN   \n",
       "\n",
       "                                          tokens_num  Report#  determinants  \n",
       "0  [10421, 5344, 4306, 2217, 10421, 6946, 7500, 1...        0      0.000189  \n",
       "1  [3001, 1357, 9240, 6615, 3541, 277, 5870, 1218...        1           inf  \n",
       "2  [2444, 10421, 5475, 3214, 3984, 1961, 6615, 77...        2      0.000181  \n",
       "3  [1531, 5468, 6924, 6824, 1832, 4795, 8540, 840...        3      0.000180  \n",
       "4  [8827, 3214, 802, 5633, 9925, 8072, 4455, 7380...        4      0.000183  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
